"""
concatenate_outputs.py

Purpose:
This script concatenates multiple CSV files generated by the webinar-report-merge.py script.
It is intended to be used after processing multiple webinar reports, combining their outputs into a single CSV file.

Key features:
- Concatenates all CSV files in the specified output directory
- Preserves the header from the first file
- Sorts files alphabetically before concatenation
- Provides console output for successful concatenation or if no CSV files are found
- Assumes all CSV files in the output directory have the same structure

Usage:
Place this script in the same directory as webinar-report-merge.py and run it after processing multiple webinar reports.
The output directory and filename can be modified by changing the default parameters in the concatenate_csv_files function.
"""

import os
import pandas as pd
import glob
import logging

# Set up logging
logging.basicConfig(level=logging.DEBUG, 
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    filename='concatenate_outputs.log',
                    filemode='w')

# Create a console handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(levelname)s: %(message)s')
console_handler.setFormatter(console_formatter)

# Add console handler to the logger
logger = logging.getLogger()
logger.addHandler(console_handler)

def concatenate_csv_files(output_dir='output', output_filename='concatenated_output.csv'):
    """
    Concatenate all CSV files in the specified output directory into a single CSV file.

    Args:
    output_dir (str): The directory containing the CSV files to concatenate. Default is 'output'.
    output_filename (str): The name of the output file. Default is 'concatenated_output.csv'.

    Returns:
    None
    """
    logger.info(f"Starting concatenation process. Output directory: {output_dir}")
    
    # Get all CSV files in the output directory, sorted alphabetically
    csv_files = sorted(glob.glob(os.path.join(output_dir, '*.csv')))
    logger.debug(f"Found {len(csv_files)} CSV files: {csv_files}")
    
    # Check if any CSV files were found
    if not csv_files:
        logger.warning(f"No CSV files found in the '{output_dir}' directory.")
        return
    
    # Initialize an empty list to store individual DataFrames
    df_list = []

    # Read each CSV file and append it to the list
    for file in csv_files:
        logger.debug(f"Reading file: {file}")
        try:
            df = pd.read_csv(file)
            df_list.append(df)
            logger.debug(f"Successfully read {file}. Shape: {df.shape}")
        except Exception as e:
            logger.error(f"Error reading {file}: {str(e)}")
    
    # Concatenate all DataFrames in the list
    logger.info("Concatenating DataFrames...")
    try:
        concatenated_df = pd.concat(df_list, ignore_index=True)
        logger.debug(f"Concatenation successful. Shape of concatenated DataFrame: {concatenated_df.shape}")
    except Exception as e:
        logger.error(f"Error during concatenation: {str(e)}")
        return
    
    # Determine the full path for the output file
    output_path = os.path.join(os.getcwd(), output_filename)

    # Save the concatenated DataFrame to a new CSV file
    logger.info(f"Saving concatenated data to {output_path}")
    try:
        concatenated_df.to_csv(output_path, index=False)
        logger.info(f"Successfully saved concatenated data. Output file: {output_path}")
    except Exception as e:
        logger.error(f"Error saving concatenated data: {str(e)}")
        return
    
    # Print success message
    logger.info(f"Successfully concatenated {len(csv_files)} CSV files.")
    logger.info(f"Output saved to: {output_path}")

if __name__ == "__main__":
    logger.info("Starting concatenate_outputs.py")
    concatenate_csv_files()
    logger.info("concatenate_outputs.py completed")
